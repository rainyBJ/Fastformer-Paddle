 Ed: 0, train_loss: 1.70222, acc: 0.14062
 Ed: 640, train_loss: 2.09981, acc: 0.21875
 Ed: 1280, train_loss: 1.89833, acc: 0.22991
 Ed: 1920, train_loss: 1.82968, acc: 0.22631
 Ed: 2560, train_loss: 1.79591, acc: 0.22180
 Ed: 3200, train_loss: 1.76191, acc: 0.22610
 Ed: 3840, train_loss: 1.73341, acc: 0.23079
 Ed: 4480, train_loss: 1.70474, acc: 0.24142
 Ed: 5120, train_loss: 1.68085, acc: 0.25174
 Ed: 5760, train_loss: 1.65981, acc: 0.25721
 Ed: 6400, train_loss: 1.64569, acc: 0.26238
 Ed: 7040, train_loss: 1.63260, acc: 0.26999
 Ed: 7680, train_loss: 1.62244, acc: 0.27286
 Ed: 8320, train_loss: 1.60842, acc: 0.27696
 Ed: 8960, train_loss: 1.60270, acc: 0.28059
 Ed: 9600, train_loss: 1.59607, acc: 0.28301
 Ed: 10240, train_loss: 1.58715, acc: 0.28620
 Ed: 10880, train_loss: 1.57850, acc: 0.29267
 Ed: 11520, train_loss: 1.56771, acc: 0.29877
 Ed: 12160, train_loss: 1.56281, acc: 0.30039
 Ed: 12800, train_loss: 1.55751, acc: 0.30247
 Ed: 13440, train_loss: 1.55108, acc: 0.30672
 Ed: 14080, train_loss: 1.54586, acc: 0.30967
 Ed: 14720, train_loss: 1.53901, acc: 0.31318
 Ed: 15360, train_loss: 1.53089, acc: 0.31645
 Ed: 16000, train_loss: 1.52696, acc: 0.31810
 Ed: 16640, train_loss: 1.52307, acc: 0.31867
 Ed: 17280, train_loss: 1.51574, acc: 0.32219
 Ed: 17920, train_loss: 1.51186, acc: 0.32446
 Ed: 18560, train_loss: 1.50616, acc: 0.32748
 Ed: 19200, train_loss: 1.50164, acc: 0.32979
 Ed: 19840, train_loss: 1.49582, acc: 0.33305
 Ed: 20480, train_loss: 1.49067, acc: 0.33538
 Ed: 21120, train_loss: 1.48660, acc: 0.33747
 Ed: 21760, train_loss: 1.48031, acc: 0.33999
 Ed: 22400, train_loss: 1.47670, acc: 0.34170
 Ed: 23040, train_loss: 1.47182, acc: 0.34392
 Ed: 23680, train_loss: 1.46835, acc: 0.34514
 Ed: 24320, train_loss: 1.46400, acc: 0.34773
 Ed: 24960, train_loss: 1.46274, acc: 0.34922
 Ed: 25600, train_loss: 1.46021, acc: 0.35022
 Ed: 26240, train_loss: 1.45670, acc: 0.35189
 Ed: 26880, train_loss: 1.45362, acc: 0.35347
 Ed: 27520, train_loss: 1.45061, acc: 0.35481
 Ed: 28160, train_loss: 1.44803, acc: 0.35629
 Ed: 28800, train_loss: 1.44502, acc: 0.35789
 Ed: 29440, train_loss: 1.44106, acc: 0.35971
 Ed: 30080, train_loss: 1.43915, acc: 0.36040
 Ed: 30720, train_loss: 1.43944, acc: 0.36067
 Ed: 31360, train_loss: 1.43915, acc: 0.36240
 Ed: 32000, train_loss: 1.43736, acc: 0.36365
 Ed: 32640, train_loss: 1.43537, acc: 0.36415
 Ed: 33280, train_loss: 1.43344, acc: 0.36474
 Ed: 33920, train_loss: 1.43104, acc: 0.36558
 Ed: 34560, train_loss: 1.42854, acc: 0.36668
 Ed: 35200, train_loss: 1.42751, acc: 0.36788
 Ed: 35840, train_loss: 1.42460, acc: 0.36904
 Ed: 36480, train_loss: 1.42299, acc: 0.36966
 Ed: 37120, train_loss: 1.42133, acc: 0.37024
 Ed: 37760, train_loss: 1.42020, acc: 0.37090
 Ed: 38400, train_loss: 1.41869, acc: 0.37172
 Ed: 39040, train_loss: 1.41651, acc: 0.37265
 Ed: 39680, train_loss: 1.41438, acc: 0.37354
accuracy: 
0.3992
macrof: 
0.4133
 Ed: 0, train_loss: 1.05090, acc: 0.54688
 Ed: 640, train_loss: 1.15512, acc: 0.47727
 Ed: 1280, train_loss: 1.20317, acc: 0.46205
 Ed: 1920, train_loss: 1.21186, acc: 0.45867
 Ed: 2560, train_loss: 1.19923, acc: 0.46189
 Ed: 3200, train_loss: 1.18784, acc: 0.46722
 Ed: 3840, train_loss: 1.19170, acc: 0.46516
 Ed: 4480, train_loss: 1.19451, acc: 0.46501
 Ed: 5120, train_loss: 1.19391, acc: 0.46508
 Ed: 5760, train_loss: 1.19738, acc: 0.46411
 Ed: 6400, train_loss: 1.20466, acc: 0.46318
 Ed: 7040, train_loss: 1.21050, acc: 0.46073
 Ed: 7680, train_loss: 1.21247, acc: 0.45997
 Ed: 8320, train_loss: 1.22226, acc: 0.45527
 Ed: 8960, train_loss: 1.22689, acc: 0.45180
 Ed: 9600, train_loss: 1.22421, acc: 0.45178
 Ed: 10240, train_loss: 1.23325, acc: 0.45148
 Ed: 10880, train_loss: 1.23284, acc: 0.45221
 Ed: 11520, train_loss: 1.22845, acc: 0.45494
 Ed: 12160, train_loss: 1.22925, acc: 0.45321
 Ed: 12800, train_loss: 1.22896, acc: 0.45351
 Ed: 13440, train_loss: 1.22880, acc: 0.45446
 Ed: 14080, train_loss: 1.22711, acc: 0.45595
 Ed: 14720, train_loss: 1.22397, acc: 0.45718
 Ed: 15360, train_loss: 1.22054, acc: 0.45812
 Ed: 16000, train_loss: 1.21828, acc: 0.45954
 Ed: 16640, train_loss: 1.21568, acc: 0.46169
 Ed: 17280, train_loss: 1.21379, acc: 0.46310
 Ed: 17920, train_loss: 1.21267, acc: 0.46391
 Ed: 18560, train_loss: 1.21103, acc: 0.46467
 Ed: 19200, train_loss: 1.21018, acc: 0.46605
 Ed: 19840, train_loss: 1.20787, acc: 0.46759
 Ed: 20480, train_loss: 1.20985, acc: 0.46695
 Ed: 21120, train_loss: 1.20721, acc: 0.46917
 Ed: 21760, train_loss: 1.20706, acc: 0.47081
 Ed: 22400, train_loss: 1.20712, acc: 0.47120
 Ed: 23040, train_loss: 1.20756, acc: 0.47126
 Ed: 23680, train_loss: 1.20786, acc: 0.47128
 Ed: 24320, train_loss: 1.20554, acc: 0.47236
 Ed: 24960, train_loss: 1.20323, acc: 0.47375
 Ed: 25600, train_loss: 1.20123, acc: 0.47436
 Ed: 26240, train_loss: 1.19980, acc: 0.47521
 Ed: 26880, train_loss: 1.19937, acc: 0.47491
 Ed: 27520, train_loss: 1.19949, acc: 0.47455
 Ed: 28160, train_loss: 1.19885, acc: 0.47527
 Ed: 28800, train_loss: 1.19735, acc: 0.47585
 Ed: 29440, train_loss: 1.19602, acc: 0.47685
 Ed: 30080, train_loss: 1.19512, acc: 0.47718
 Ed: 30720, train_loss: 1.19468, acc: 0.47677
 Ed: 31360, train_loss: 1.19384, acc: 0.47734
 Ed: 32000, train_loss: 1.19324, acc: 0.47751
 Ed: 32640, train_loss: 1.19191, acc: 0.47884
 Ed: 33280, train_loss: 1.19149, acc: 0.47949
 Ed: 33920, train_loss: 1.19034, acc: 0.47987
 Ed: 34560, train_loss: 1.18966, acc: 0.48010
 Ed: 35200, train_loss: 1.18900, acc: 0.48009
 Ed: 35840, train_loss: 1.18824, acc: 0.48059
 Ed: 36480, train_loss: 1.18894, acc: 0.48033
 Ed: 37120, train_loss: 1.18888, acc: 0.47986
 Ed: 37760, train_loss: 1.18796, acc: 0.47946
 Ed: 38400, train_loss: 1.18713, acc: 0.47977
 Ed: 39040, train_loss: 1.18566, acc: 0.48031
 Ed: 39680, train_loss: 1.18582, acc: 0.47947
accuracy: 
0.4086
macrof: 
0.4297
 Ed: 0, train_loss: 1.04510, acc: 0.51562
 Ed: 640, train_loss: 1.05481, acc: 0.54119
 Ed: 1280, train_loss: 1.01373, acc: 0.56250
 Ed: 1920, train_loss: 1.00201, acc: 0.57107
 Ed: 2560, train_loss: 1.02671, acc: 0.56059
 Ed: 3200, train_loss: 1.03648, acc: 0.54933
 Ed: 3840, train_loss: 1.04712, acc: 0.54329
 Ed: 4480, train_loss: 1.04645, acc: 0.54665
 Ed: 5120, train_loss: 1.04603, acc: 0.54707
 Ed: 5760, train_loss: 1.04418, acc: 0.54670
 Ed: 6400, train_loss: 1.04450, acc: 0.54811
 Ed: 7040, train_loss: 1.04194, acc: 0.54899
 Ed: 7680, train_loss: 1.03971, acc: 0.54842
 Ed: 8320, train_loss: 1.03643, acc: 0.55212
 Ed: 8960, train_loss: 1.03574, acc: 0.55142
 Ed: 9600, train_loss: 1.03704, acc: 0.54925
 Ed: 10240, train_loss: 1.03827, acc: 0.55047
 Ed: 10880, train_loss: 1.03780, acc: 0.55090
 Ed: 11520, train_loss: 1.03889, acc: 0.55050
 Ed: 12160, train_loss: 1.04300, acc: 0.54957
 Ed: 12800, train_loss: 1.04728, acc: 0.54890
 Ed: 13440, train_loss: 1.05244, acc: 0.54547
 Ed: 14080, train_loss: 1.05995, acc: 0.54440
 Ed: 14720, train_loss: 1.06156, acc: 0.54261
 Ed: 15360, train_loss: 1.06932, acc: 0.54098
 Ed: 16000, train_loss: 1.06900, acc: 0.54133
 Ed: 16640, train_loss: 1.07131, acc: 0.54047
 Ed: 17280, train_loss: 1.07457, acc: 0.54019
 Ed: 17920, train_loss: 1.07796, acc: 0.53815
 Ed: 18560, train_loss: 1.07865, acc: 0.53807
 Ed: 19200, train_loss: 1.08336, acc: 0.53551
 Ed: 19840, train_loss: 1.08456, acc: 0.53462
 Ed: 20480, train_loss: 1.08586, acc: 0.53354
 Ed: 21120, train_loss: 1.08483, acc: 0.53352
 Ed: 21760, train_loss: 1.08555, acc: 0.53308
 Ed: 22400, train_loss: 1.08394, acc: 0.53352
 Ed: 23040, train_loss: 1.08432, acc: 0.53359
 Ed: 23680, train_loss: 1.08332, acc: 0.53293
 Ed: 24320, train_loss: 1.08348, acc: 0.53285
 Ed: 24960, train_loss: 1.08173, acc: 0.53357
 Ed: 25600, train_loss: 1.08243, acc: 0.53367
 Ed: 26240, train_loss: 1.08193, acc: 0.53315
 Ed: 26880, train_loss: 1.08196, acc: 0.53318
 Ed: 27520, train_loss: 1.08040, acc: 0.53379
 Ed: 28160, train_loss: 1.07925, acc: 0.53359
 Ed: 28800, train_loss: 1.07732, acc: 0.53482
 Ed: 29440, train_loss: 1.07713, acc: 0.53498
 Ed: 30080, train_loss: 1.07599, acc: 0.53536
 Ed: 30720, train_loss: 1.07468, acc: 0.53560
 Ed: 31360, train_loss: 1.07518, acc: 0.53475
 Ed: 32000, train_loss: 1.07516, acc: 0.53428
 Ed: 32640, train_loss: 1.07459, acc: 0.53471
 Ed: 33280, train_loss: 1.07425, acc: 0.53458
 Ed: 33920, train_loss: 1.07384, acc: 0.53490
 Ed: 34560, train_loss: 1.07640, acc: 0.53457
 Ed: 35200, train_loss: 1.07516, acc: 0.53539
 Ed: 35840, train_loss: 1.07436, acc: 0.53604
 Ed: 36480, train_loss: 1.07384, acc: 0.53607
 Ed: 37120, train_loss: 1.07415, acc: 0.53579
 Ed: 37760, train_loss: 1.07412, acc: 0.53561
 Ed: 38400, train_loss: 1.07386, acc: 0.53554
 Ed: 39040, train_loss: 1.07374, acc: 0.53560
 Ed: 39680, train_loss: 1.07419, acc: 0.53560
accuracy: 
0.4382
macrof: 
0.4378
